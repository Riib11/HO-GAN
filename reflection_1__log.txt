Unable to init server: Could not connect: Connection refused
Unable to init server: Could not connect: Connection refused

(dcgan_custom.py:101634): Gdk-CRITICAL **: 15:01:53.654: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed

(dcgan_custom.py:101634): Gdk-CRITICAL **: 15:01:53.654: gdk_cursor_new_for_display: assertion 'GDK_IS_DISPLAY (display)' failed
Using TensorFlow backend.
  0%|          | 0/1000 [00:00<?, ?it/s]100%|██████████| 1000/1000 [00:00<00:00, 12087.89it/s]
WARNING:tensorflow:From /home/blancheh/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/blancheh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-05-09 15:01:54.021657: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-05-09 15:01:54.046540: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3393280000 Hz
2019-05-09 15:01:54.048237: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2eafdc0 executing computations on platform Host. Devices:
2019-05-09 15:01:54.048287: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
WARNING:tensorflow:From /home/blancheh/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
loading images in directory: reflected
loaded 1 classes: ['reflected']
loaded 1000 images
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 7, 7, 128)         204928    
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 128)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 7, 7, 128)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 256)         819456    
_________________________________________________________________
leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 256)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   
_________________________________________________________________
leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 512)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 4, 4, 512)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 8192)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 8193      
_________________________________________________________________
activation_1 (Activation)    (None, 1)                 0         
=================================================================
Total params: 4,311,553
Trainable params: 4,311,553
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_2 (Dense)              (None, 12544)             1266944   
_________________________________________________________________
batch_normalization_1 (Batch (None, 12544)             50176     
_________________________________________________________________
activation_2 (Activation)    (None, 12544)             0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 7, 7, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 7, 7, 256)         0         
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 14, 14, 256)       0         
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 14, 14, 128)       819328    
_________________________________________________________________
batch_normalization_2 (Batch (None, 14, 14, 128)       512       
_________________________________________________________________
activation_3 (Activation)    (None, 14, 14, 128)       0         
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 28, 28, 64)        204864    
_________________________________________________________________
batch_normalization_3 (Batch (None, 28, 28, 64)        256       
_________________________________________________________________
activation_4 (Activation)    (None, 28, 28, 64)        0         
_________________________________________________________________
conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        51232     
_________________________________________________________________
batch_normalization_4 (Batch (None, 28, 28, 32)        128       
_________________________________________________________________
activation_5 (Activation)    (None, 28, 28, 32)        0         
_________________________________________________________________
conv2d_transpose_4 (Conv2DTr (None, 28, 28, 1)         801       
_________________________________________________________________
activation_6 (Activation)    (None, 28, 28, 1)         0         
=================================================================
Total params: 2,394,241
Trainable params: 2,368,705
Non-trainable params: 25,536
_________________________________________________________________
0: [D loss: 0.694475, acc: 0.453125]  [A loss: 0.706376, acc: 0.250000]
1: [D loss: 0.618476, acc: 0.500000]  [A loss: 0.386194, acc: 1.000000]
2: [D loss: 1.620951, acc: 0.500000]  [A loss: 1.460330, acc: 0.000000]
3: [D loss: 0.608630, acc: 0.500000]  [A loss: 0.586574, acc: 1.000000]
4: [D loss: 0.811037, acc: 0.500000]  [A loss: 3.160380, acc: 0.000000]
5: [D loss: 0.541724, acc: 0.500000]  [A loss: 0.071002, acc: 1.000000]
6: [D loss: 0.861864, acc: 0.500000]  [A loss: 0.784789, acc: 0.187500]
7: [D loss: 0.850554, acc: 0.500000]  [A loss: 6.078428, acc: 0.000000]
8: [D loss: 0.745675, acc: 0.531250]  [A loss: 0.026365, acc: 1.000000]
9: [D loss: 1.829519, acc: 0.500000]  [A loss: 1.284596, acc: 0.000000]
10: [D loss: 0.675730, acc: 0.500000]  [A loss: 1.261311, acc: 0.000000]
11: [D loss: 0.815898, acc: 0.500000]  [A loss: 5.519341, acc: 0.000000]
12: [D loss: 0.768034, acc: 0.531250]  [A loss: 0.026332, acc: 1.000000]
13: [D loss: 1.607275, acc: 0.500000]  [A loss: 1.263165, acc: 0.000000]
14: [D loss: 0.755551, acc: 0.500000]  [A loss: 3.060435, acc: 0.000000]
15: [D loss: 0.654288, acc: 0.531250]  [A loss: 1.987550, acc: 0.000000]
16: [D loss: 1.041209, acc: 0.500000]  [A loss: 10.144279, acc: 0.000000]
17: [D loss: 2.164299, acc: 0.500000]  [A loss: 0.004037, acc: 1.000000]
18: [D loss: 2.162667, acc: 0.500000]  [A loss: 0.247208, acc: 1.000000]
19: [D loss: 0.989148, acc: 0.500000]  [A loss: 1.129669, acc: 0.031250]
20: [D loss: 0.710360, acc: 0.500000]  [A loss: 1.040832, acc: 0.062500]
21: [D loss: 0.802624, acc: 0.515625]  [A loss: 2.269086, acc: 0.000000]
22: [D loss: 0.624500, acc: 0.578125]  [A loss: 1.145612, acc: 0.000000]
23: [D loss: 0.951509, acc: 0.500000]  [A loss: 3.904526, acc: 0.000000]
24: [D loss: 0.948735, acc: 0.500000]  [A loss: 0.055556, acc: 1.000000]
25: [D loss: 1.689130, acc: 0.500000]  [A loss: 1.274840, acc: 0.000000]
26: [D loss: 0.624015, acc: 0.578125]  [A loss: 1.297583, acc: 0.000000]
27: [D loss: 0.796340, acc: 0.546875]  [A loss: 2.392810, acc: 0.000000]
28: [D loss: 0.741393, acc: 0.562500]  [A loss: 1.722855, acc: 0.000000]
29: [D loss: 0.900961, acc: 0.484375]  [A loss: 3.334622, acc: 0.000000]
30: [D loss: 0.670950, acc: 0.593750]  [A loss: 0.263425, acc: 1.000000]
31: [D loss: 1.359773, acc: 0.500000]  [A loss: 6.406677, acc: 0.000000]
32: [D loss: 1.384712, acc: 0.500000]  [A loss: 0.015101, acc: 1.000000]
33: [D loss: 2.505095, acc: 0.500000]  [A loss: 1.026158, acc: 0.156250]
34: [D loss: 0.845462, acc: 0.468750]  [A loss: 1.913928, acc: 0.000000]
35: [D loss: 0.694665, acc: 0.531250]  [A loss: 1.311951, acc: 0.062500]
36: [D loss: 0.865968, acc: 0.500000]  [A loss: 2.467858, acc: 0.000000]
37: [D loss: 0.610675, acc: 0.656250]  [A loss: 0.503735, acc: 0.812500]
38: [D loss: 1.295353, acc: 0.500000]  [A loss: 5.268031, acc: 0.000000]
39: [D loss: 1.408034, acc: 0.515625]  [A loss: 0.010603, acc: 1.000000]
40: [D loss: 3.137662, acc: 0.500000]  [A loss: 0.773789, acc: 0.406250]
41: [D loss: 0.835618, acc: 0.531250]  [A loss: 1.642727, acc: 0.000000]
42: [D loss: 0.745964, acc: 0.593750]  [A loss: 0.672843, acc: 0.593750]
43: [D loss: 1.003563, acc: 0.500000]  [A loss: 2.663385, acc: 0.000000]
44: [D loss: 0.707137, acc: 0.531250]  [A loss: 0.752835, acc: 0.343750]
45: [D loss: 1.202433, acc: 0.484375]  [A loss: 4.745897, acc: 0.000000]
46: [D loss: 1.266815, acc: 0.406250]  [A loss: 0.011373, acc: 1.000000]
47: [D loss: 2.953071, acc: 0.500000]  [A loss: 1.107280, acc: 0.156250]
48: [D loss: 0.903357, acc: 0.468750]  [A loss: 1.479541, acc: 0.062500]
49: [D loss: 0.896931, acc: 0.484375]  [A loss: 2.525316, acc: 0.000000]
50: [D loss: 0.784850, acc: 0.546875]  [A loss: 1.795900, acc: 0.000000]
51: [D loss: 1.065379, acc: 0.500000]  [A loss: 3.250441, acc: 0.000000]
52: [D loss: 0.875636, acc: 0.531250]  [A loss: 0.125568, acc: 1.000000]
53: [D loss: 1.756046, acc: 0.500000]  [A loss: 3.347779, acc: 0.000000]
54: [D loss: 0.834820, acc: 0.500000]  [A loss: 0.140223, acc: 1.000000]
55: [D loss: 1.615379, acc: 0.500000]  [A loss: 2.877039, acc: 0.000000]
56: [D loss: 0.847432, acc: 0.468750]  [A loss: 0.154918, acc: 1.000000]
57: [D loss: 1.553288, acc: 0.500000]  [A loss: 2.970520, acc: 0.000000]
58: [D loss: 0.876355, acc: 0.515625]  [A loss: 0.081610, acc: 1.000000]
59: [D loss: 1.989598, acc: 0.500000]  [A loss: 2.006052, acc: 0.031250]
60: [D loss: 0.820275, acc: 0.515625]  [A loss: 0.350597, acc: 0.968750]
61: [D loss: 1.365957, acc: 0.484375]  [A loss: 2.630830, acc: 0.000000]
62: [D loss: 0.780806, acc: 0.593750]  [A loss: 0.248863, acc: 1.000000]
63: [D loss: 1.575900, acc: 0.500000]  [A loss: 2.739695, acc: 0.000000]
64: [D loss: 1.054114, acc: 0.578125]  [A loss: 0.060311, acc: 1.000000]
65: [D loss: 2.243671, acc: 0.500000]  [A loss: 1.187793, acc: 0.093750]
66: [D loss: 0.820640, acc: 0.515625]  [A loss: 0.949405, acc: 0.281250]
67: [D loss: 1.057711, acc: 0.484375]  [A loss: 1.848639, acc: 0.000000]
68: [D loss: 0.741507, acc: 0.578125]  [A loss: 1.575302, acc: 0.000000]
69: [D loss: 0.989592, acc: 0.500000]  [A loss: 2.399570, acc: 0.000000]
70: [D loss: 0.866285, acc: 0.437500]  [A loss: 1.177791, acc: 0.125000]
71: [D loss: 1.474147, acc: 0.453125]  [A loss: 4.036911, acc: 0.000000]
72: [D loss: 0.959917, acc: 0.437500]  [A loss: 0.066371, acc: 1.000000]
73: [D loss: 2.402083, acc: 0.500000]  [A loss: 4.570545, acc: 0.000000]
74: [D loss: 1.302513, acc: 0.468750]  [A loss: 0.003148, acc: 1.000000]
75: [D loss: 3.850901, acc: 0.500000]  [A loss: 0.517839, acc: 0.812500]
76: [D loss: 1.249791, acc: 0.515625]  [A loss: 2.922697, acc: 0.000000]
77: [D loss: 0.877725, acc: 0.453125]  [A loss: 0.247166, acc: 0.968750]
78: [D loss: 1.579394, acc: 0.500000]  [A loss: 2.314896, acc: 0.031250]
79: [D loss: 0.833166, acc: 0.515625]  [A loss: 0.445798, acc: 0.781250]
80: [D loss: 1.215499, acc: 0.484375]  [A loss: 3.356692, acc: 0.000000]
81: [D loss: 0.871434, acc: 0.453125]  [A loss: 0.335835, acc: 0.906250]
82: [D loss: 1.408650, acc: 0.515625]  [A loss: 3.497850, acc: 0.000000]
83: [D loss: 1.035214, acc: 0.515625]  [A loss: 0.042610, acc: 1.000000]
84: [D loss: 2.075329, acc: 0.500000]  [A loss: 1.390037, acc: 0.062500]
85: [D loss: 0.872840, acc: 0.453125]  [A loss: 0.937555, acc: 0.250000]
86: [D loss: 1.084693, acc: 0.484375]  [A loss: 2.143613, acc: 0.000000]
87: [D loss: 0.818781, acc: 0.500000]  [A loss: 0.614355, acc: 0.718750]
88: [D loss: 1.200526, acc: 0.468750]  [A loss: 3.355054, acc: 0.000000]
89: [D loss: 0.864930, acc: 0.578125]  [A loss: 0.038283, acc: 1.000000]
90: [D loss: 2.125135, acc: 0.500000]  [A loss: 1.296468, acc: 0.062500]
91: [D loss: 0.878475, acc: 0.500000]  [A loss: 1.472006, acc: 0.093750]
92: [D loss: 0.894844, acc: 0.515625]  [A loss: 1.627347, acc: 0.093750]
93: [D loss: 0.751823, acc: 0.562500]  [A loss: 0.564480, acc: 0.656250]
94: [D loss: 1.251010, acc: 0.515625]  [A loss: 3.800201, acc: 0.000000]
95: [D loss: 0.742188, acc: 0.593750]  [A loss: 0.036638, acc: 1.000000]
96: [D loss: 1.971780, acc: 0.500000]  [A loss: 1.057799, acc: 0.093750]
97: [D loss: 0.742664, acc: 0.468750]  [A loss: 1.514340, acc: 0.031250]
98: [D loss: 0.832987, acc: 0.484375]  [A loss: 1.487418, acc: 0.000000]
99: [D loss: 0.918172, acc: 0.500000]  [A loss: 2.225740, acc: 0.000000]
100: [D loss: 0.811987, acc: 0.562500]  [A loss: 1.200090, acc: 0.187500]
101: [D loss: 1.094278, acc: 0.484375]  [A loss: 3.148758, acc: 0.000000]
102: [D loss: 0.870396, acc: 0.500000]  [A loss: 0.015199, acc: 1.000000]
103: [D loss: 2.625052, acc: 0.500000]  [A loss: 0.938438, acc: 0.218750]
104: [D loss: 0.945968, acc: 0.531250]  [A loss: 2.806754, acc: 0.000000]
105: [D loss: 0.882029, acc: 0.546875]  [A loss: 0.102556, acc: 1.000000]
106: [D loss: 1.489921, acc: 0.500000]  [A loss: 1.836331, acc: 0.062500]
107: [D loss: 0.631578, acc: 0.546875]  [A loss: 0.996913, acc: 0.281250]
108: [D loss: 1.017112, acc: 0.484375]  [A loss: 1.670664, acc: 0.031250]
109: [D loss: 0.958752, acc: 0.515625]  [A loss: 3.000598, acc: 0.000000]
110: [D loss: 0.914263, acc: 0.515625]  [A loss: 0.052984, acc: 1.000000]
111: [D loss: 1.830973, acc: 0.500000]  [A loss: 2.246716, acc: 0.000000]
112: [D loss: 0.596604, acc: 0.578125]  [A loss: 0.816450, acc: 0.281250]
113: [D loss: 0.906406, acc: 0.484375]  [A loss: 0.733895, acc: 0.562500]
114: [D loss: 0.979816, acc: 0.468750]  [A loss: 1.763013, acc: 0.000000]
115: [D loss: 0.849257, acc: 0.500000]  [A loss: 0.313333, acc: 0.937500]
116: [D loss: 1.235139, acc: 0.500000]  [A loss: 3.220580, acc: 0.000000]
117: [D loss: 1.074960, acc: 0.656250]  [A loss: 0.002909, acc: 1.000000]
118: [D loss: 3.377523, acc: 0.500000]  [A loss: 0.156991, acc: 1.000000]
119: [D loss: 1.351704, acc: 0.500000]  [A loss: 0.949429, acc: 0.187500]
120: [D loss: 0.785125, acc: 0.515625]  [A loss: 1.017181, acc: 0.218750]
121: [D loss: 0.685658, acc: 0.515625]  [A loss: 0.570836, acc: 0.718750]
122: [D loss: 0.987358, acc: 0.500000]  [A loss: 1.812144, acc: 0.031250]
123: [D loss: 0.735628, acc: 0.531250]  [A loss: 0.824011, acc: 0.406250]
124: [D loss: 0.829319, acc: 0.515625]  [A loss: 2.355093, acc: 0.000000]
125: [D loss: 0.794486, acc: 0.515625]  [A loss: 0.727249, acc: 0.687500]
126: [D loss: 1.243485, acc: 0.500000]  [A loss: 4.183681, acc: 0.000000]
127: [D loss: 1.040594, acc: 0.578125]  [A loss: 0.007343, acc: 1.000000]
128: [D loss: 2.823912, acc: 0.500000]  [A loss: 0.254578, acc: 0.968750]
129: [D loss: 1.102859, acc: 0.500000]  [A loss: 1.007763, acc: 0.281250]
130: [D loss: 0.827749, acc: 0.546875]  [A loss: 0.679836, acc: 0.562500]
131: [D loss: 0.923212, acc: 0.515625]  [A loss: 1.887864, acc: 0.031250]
132: [D loss: 0.678290, acc: 0.531250]  [A loss: 1.567521, acc: 0.062500]
133: [D loss: 0.620747, acc: 0.531250]  [A loss: 1.040703, acc: 0.187500]
134: [D loss: 0.811747, acc: 0.500000]  [A loss: 1.923494, acc: 0.000000]
135: [D loss: 0.611375, acc: 0.531250]  [A loss: 0.379582, acc: 0.875000]
136: [D loss: 0.945576, acc: 0.500000]  [A loss: 1.735280, acc: 0.000000]
137: [D loss: 0.584165, acc: 0.531250]  [A loss: 0.640322, acc: 0.687500]
138: [D loss: 0.783146, acc: 0.484375]  [A loss: 1.536679, acc: 0.062500]
139: [D loss: 0.615767, acc: 0.546875]  [A loss: 0.441784, acc: 0.906250]
140: [D loss: 0.972063, acc: 0.500000]  [A loss: 2.538817, acc: 0.000000]
141: [D loss: 0.751860, acc: 0.531250]  [A loss: 0.075192, acc: 1.000000]
142: [D loss: 1.598565, acc: 0.500000]  [A loss: 1.122397, acc: 0.187500]
143: [D loss: 0.748329, acc: 0.484375]  [A loss: 1.529064, acc: 0.031250]
144: [D loss: 0.598979, acc: 0.531250]  [A loss: 1.043902, acc: 0.187500]
145: [D loss: 0.668464, acc: 0.500000]  [A loss: 2.091647, acc: 0.000000]
146: [D loss: 0.562794, acc: 0.609375]  [A loss: 0.273277, acc: 1.000000]
147: [D loss: 0.902513, acc: 0.500000]  [A loss: 1.684622, acc: 0.000000]
148: [D loss: 0.662640, acc: 0.609375]  [A loss: 0.088227, acc: 1.000000]
149: [D loss: 1.554625, acc: 0.500000]  [A loss: 0.877950, acc: 0.250000]
150: [D loss: 0.641948, acc: 0.546875]  [A loss: 1.593950, acc: 0.031250]
151: [D loss: 0.675046, acc: 0.468750]  [A loss: 0.341612, acc: 0.937500]
152: [D loss: 0.899809, acc: 0.500000]  [A loss: 1.880198, acc: 0.000000]
153: [D loss: 0.612600, acc: 0.640625]  [A loss: 0.151017, acc: 1.000000]
154: [D loss: 1.240036, acc: 0.500000]  [A loss: 0.871110, acc: 0.281250]
155: [D loss: 0.697777, acc: 0.484375]  [A loss: 1.379296, acc: 0.000000]
156: [D loss: 0.549060, acc: 0.625000]  [A loss: 0.995425, acc: 0.156250]
157: [D loss: 0.690964, acc: 0.515625]  [A loss: 1.172609, acc: 0.031250]
158: [D loss: 0.651034, acc: 0.546875]  [A loss: 2.246228, acc: 0.000000]
159: [D loss: 0.541445, acc: 0.609375]  [A loss: 0.517952, acc: 0.875000]
160: [D loss: 0.733007, acc: 0.500000]  [A loss: 2.253573, acc: 0.000000]
161: [D loss: 0.699769, acc: 0.640625]  [A loss: 0.036717, acc: 1.000000]
162: [D loss: 2.099942, acc: 0.500000]  [A loss: 0.446556, acc: 0.906250]
163: [D loss: 0.838890, acc: 0.500000]  [A loss: 1.251078, acc: 0.031250]
164: [D loss: 0.513961, acc: 0.609375]  [A loss: 0.964257, acc: 0.125000]
165: [D loss: 0.559098, acc: 0.531250]  [A loss: 1.055409, acc: 0.062500]
166: [D loss: 0.602170, acc: 0.515625]  [A loss: 1.683001, acc: 0.000000]
167: [D loss: 0.588796, acc: 0.562500]  [A loss: 0.460371, acc: 0.906250]
168: [D loss: 0.897408, acc: 0.500000]  [A loss: 1.584301, acc: 0.000000]
169: [D loss: 0.624827, acc: 0.515625]  [A loss: 0.520129, acc: 0.843750]
170: [D loss: 0.940610, acc: 0.500000]  [A loss: 2.240296, acc: 0.000000]
171: [D loss: 0.595140, acc: 0.750000]  [A loss: 0.227148, acc: 1.000000]
172: [D loss: 1.070242, acc: 0.500000]  [A loss: 1.025023, acc: 0.125000]
173: [D loss: 0.564785, acc: 0.546875]  [A loss: 1.401284, acc: 0.000000]
174: [D loss: 0.548123, acc: 0.531250]  [A loss: 0.532774, acc: 0.812500]
175: [D loss: 0.777648, acc: 0.515625]  [A loss: 1.828652, acc: 0.000000]
176: [D loss: 0.460345, acc: 0.609375]  [A loss: 0.810443, acc: 0.375000]
177: [D loss: 0.681267, acc: 0.515625]  [A loss: 1.799174, acc: 0.000000]
178: [D loss: 0.498447, acc: 0.625000]  [A loss: 0.343455, acc: 0.968750]
179: [D loss: 0.867989, acc: 0.500000]  [A loss: 1.205866, acc: 0.031250]
180: [D loss: 0.549293, acc: 0.484375]  [A loss: 1.102045, acc: 0.031250]
181: [D loss: 0.683244, acc: 0.515625]  [A loss: 2.834003, acc: 0.000000]
182: [D loss: 0.534163, acc: 0.671875]  [A loss: 0.085859, acc: 1.000000]
183: [D loss: 1.374735, acc: 0.500000]  [A loss: 0.797364, acc: 0.343750]
184: [D loss: 0.567261, acc: 0.546875]  [A loss: 1.310347, acc: 0.031250]
185: [D loss: 0.440640, acc: 0.640625]  [A loss: 1.252274, acc: 0.000000]
186: [D loss: 0.448276, acc: 0.640625]  [A loss: 1.679028, acc: 0.000000]
187: [D loss: 0.523591, acc: 0.609375]  [A loss: 0.498452, acc: 0.875000]
188: [D loss: 0.830914, acc: 0.500000]  [A loss: 2.227097, acc: 0.000000]
189: [D loss: 0.462682, acc: 0.687500]  [A loss: 1.704102, acc: 0.031250]
190: [D loss: 0.690081, acc: 0.515625]  [A loss: 2.034069, acc: 0.000000]
191: [D loss: 0.446728, acc: 0.671875]  [A loss: 1.858327, acc: 0.000000]
192: [D loss: 0.485755, acc: 0.625000]  [A loss: 1.799446, acc: 0.000000]
193: [D loss: 0.607089, acc: 0.562500]  [A loss: 3.443008, acc: 0.000000]
194: [D loss: 0.641445, acc: 0.750000]  [A loss: 0.012654, acc: 1.000000]
195: [D loss: 2.164460, acc: 0.500000]  [A loss: 0.335518, acc: 0.968750]
196: [D loss: 0.907387, acc: 0.500000]  [A loss: 1.146346, acc: 0.062500]
197: [D loss: 0.535497, acc: 0.515625]  [A loss: 1.637862, acc: 0.000000]
198: [D loss: 0.454080, acc: 0.625000]  [A loss: 1.795630, acc: 0.000000]
199: [D loss: 0.460523, acc: 0.671875]  [A loss: 1.851683, acc: 0.031250]
200: [D loss: 0.431752, acc: 0.687500]  [A loss: 2.304141, acc: 0.000000]
201: [D loss: 0.348761, acc: 0.843750]  [A loss: 0.910878, acc: 0.343750]
202: [D loss: 0.624747, acc: 0.562500]  [A loss: 3.158648, acc: 0.000000]
203: [D loss: 0.458074, acc: 0.890625]  [A loss: 0.371901, acc: 0.968750]
204: [D loss: 1.065915, acc: 0.500000]  [A loss: 2.668402, acc: 0.000000]
205: [D loss: 0.479502, acc: 0.750000]  [A loss: 0.982273, acc: 0.281250]
206: [D loss: 0.880537, acc: 0.500000]  [A loss: 4.477201, acc: 0.000000]
207: [D loss: 0.377146, acc: 0.890625]  [A loss: 0.085743, acc: 1.000000]
208: [D loss: 1.533919, acc: 0.500000]  [A loss: 1.387699, acc: 0.062500]
209: [D loss: 0.447508, acc: 0.625000]  [A loss: 2.152445, acc: 0.000000]
210: [D loss: 0.346362, acc: 0.796875]  [A loss: 2.300789, acc: 0.000000]
211: [D loss: 0.435960, acc: 0.750000]  [A loss: 2.105757, acc: 0.000000]
212: [D loss: 0.407487, acc: 0.750000]  [A loss: 2.964746, acc: 0.000000]
213: [D loss: 0.404111, acc: 0.796875]  [A loss: 0.487666, acc: 0.781250]
214: [D loss: 0.867165, acc: 0.531250]  [A loss: 3.541883, acc: 0.000000]
215: [D loss: 0.327337, acc: 0.843750]  [A loss: 1.294092, acc: 0.156250]
216: [D loss: 0.780398, acc: 0.531250]  [A loss: 4.674190, acc: 0.000000]
217: [D loss: 0.555528, acc: 0.750000]  [A loss: 0.013234, acc: 1.000000]
218: [D loss: 1.944072, acc: 0.500000]  [A loss: 0.999003, acc: 0.281250]
219: [D loss: 0.849134, acc: 0.515625]  [A loss: 3.290286, acc: 0.000000]
220: [D loss: 0.409461, acc: 0.781250]  [A loss: 1.121450, acc: 0.218750]
221: [D loss: 0.809115, acc: 0.515625]  [A loss: 4.825068, acc: 0.000000]
222: [D loss: 0.289589, acc: 0.890625]  [A loss: 1.002084, acc: 0.281250]
223: [D loss: 1.252842, acc: 0.500000]  [A loss: 6.585325, acc: 0.000000]
224: [D loss: 0.572687, acc: 0.781250]  [A loss: 0.011616, acc: 1.000000]
225: [D loss: 3.348951, acc: 0.500000]  [A loss: 1.024972, acc: 0.312500]
226: [D loss: 1.197952, acc: 0.515625]  [A loss: 4.564441, acc: 0.000000]
227: [D loss: 0.440133, acc: 0.812500]  [A loss: 1.580833, acc: 0.187500]
228: [D loss: 1.223558, acc: 0.531250]  [A loss: 5.727827, acc: 0.000000]
229: [D loss: 0.336191, acc: 0.859375]  [A loss: 0.228549, acc: 1.000000]
230: [D loss: 1.249269, acc: 0.500000]  [A loss: 3.562671, acc: 0.000000]
231: [D loss: 0.490957, acc: 0.687500]  [A loss: 3.054669, acc: 0.000000]
232: [D loss: 0.641802, acc: 0.640625]  [A loss: 6.541968, acc: 0.000000]
233: [D loss: 0.527730, acc: 0.828125]  [A loss: 0.241747, acc: 0.937500]
234: [D loss: 1.874350, acc: 0.500000]  [A loss: 5.007908, acc: 0.000000]
235: [D loss: 0.371179, acc: 0.859375]  [A loss: 1.589106, acc: 0.156250]
236: [D loss: 1.216256, acc: 0.546875]  [A loss: 6.608741, acc: 0.000000]
237: [D loss: 0.775847, acc: 0.781250]  [A loss: 0.047499, acc: 1.000000]
238: [D loss: 2.172438, acc: 0.500000]  [A loss: 1.689156, acc: 0.062500]
239: [D loss: 0.814718, acc: 0.640625]  [A loss: 3.278957, acc: 0.000000]
240: [D loss: 0.608854, acc: 0.671875]  [A loss: 4.345306, acc: 0.000000]
241: [D loss: 0.289264, acc: 0.875000]  [A loss: 1.794457, acc: 0.125000]
242: [D loss: 1.220348, acc: 0.546875]  [A loss: 6.356329, acc: 0.000000]
243: [D loss: 0.436541, acc: 0.843750]  [A loss: 0.403906, acc: 0.843750]
244: [D loss: 1.680996, acc: 0.500000]  [A loss: 4.605936, acc: 0.000000]
245: [D loss: 0.350429, acc: 0.828125]  [A loss: 3.577522, acc: 0.000000]
246: [D loss: 0.537533, acc: 0.750000]  [A loss: 4.926942, acc: 0.000000]
247: [D loss: 0.360460, acc: 0.796875]  [A loss: 3.617525, acc: 0.000000]
248: [D loss: 0.781886, acc: 0.687500]  [A loss: 6.838996, acc: 0.000000]
249: [D loss: 0.595850, acc: 0.812500]  [A loss: 0.077972, acc: 1.000000]
250: [D loss: 2.299764, acc: 0.500000]  [A loss: 5.094035, acc: 0.000000]
251: [D loss: 0.606694, acc: 0.734375]  [A loss: 5.966990, acc: 0.000000]
252: [D loss: 0.406276, acc: 0.843750]  [A loss: 2.110427, acc: 0.093750]
253: [D loss: 1.076137, acc: 0.546875]  [A loss: 8.101412, acc: 0.000000]
254: [D loss: 0.144851, acc: 0.968750]  [A loss: 0.634724, acc: 0.656250]
255: [D loss: 1.005111, acc: 0.593750]  [A loss: 5.349068, acc: 0.000000]
256: [D loss: 0.194040, acc: 0.921875]  [A loss: 3.054511, acc: 0.000000]
257: [D loss: 0.855949, acc: 0.593750]  [A loss: 7.004318, acc: 0.000000]
258: [D loss: 0.239021, acc: 0.890625]  [A loss: 0.565557, acc: 0.718750]
259: [D loss: 1.244807, acc: 0.515625]  [A loss: 5.254485, acc: 0.000000]
260: [D loss: 0.218258, acc: 0.906250]  [A loss: 4.007645, acc: 0.000000]
261: [D loss: 0.382632, acc: 0.781250]  [A loss: 4.849130, acc: 0.000000]
262: [D loss: 0.360710, acc: 0.828125]  [A loss: 5.764292, acc: 0.000000]
263: [D loss: 0.166459, acc: 0.953125]  [A loss: 3.424551, acc: 0.000000]
264: [D loss: 0.630658, acc: 0.687500]  [A loss: 6.739745, acc: 0.000000]
265: [D loss: 0.181230, acc: 0.953125]  [A loss: 1.646888, acc: 0.156250]
266: [D loss: 1.556893, acc: 0.500000]  [A loss: 11.132656, acc: 0.000000]
267: [D loss: 1.787023, acc: 0.578125]  [A loss: 0.006632, acc: 1.000000]
268: [D loss: 3.842152, acc: 0.500000]  [A loss: 0.635880, acc: 0.562500]
269: [D loss: 1.813398, acc: 0.500000]  [A loss: 4.750413, acc: 0.000000]
270: [D loss: 0.707769, acc: 0.718750]  [A loss: 6.815717, acc: 0.000000]
271: [D loss: 0.153689, acc: 0.937500]  [A loss: 3.898525, acc: 0.000000]
272: [D loss: 0.800576, acc: 0.703125]  [A loss: 6.188184, acc: 0.000000]
273: [D loss: 0.220967, acc: 0.906250]  [A loss: 4.261833, acc: 0.000000]
274: [D loss: 0.851277, acc: 0.671875]  [A loss: 7.770183, acc: 0.000000]
275: [D loss: 0.325267, acc: 0.875000]  [A loss: 0.799294, acc: 0.625000]
276: [D loss: 1.720314, acc: 0.531250]  [A loss: 8.055228, acc: 0.000000]
277: [D loss: 0.207987, acc: 0.937500]  [A loss: 1.291693, acc: 0.281250]
278: [D loss: 0.963291, acc: 0.625000]  [A loss: 6.187127, acc: 0.000000]
279: [D loss: 0.268164, acc: 0.921875]  [A loss: 3.392501, acc: 0.031250]
280: [D loss: 0.981845, acc: 0.625000]  [A loss: 8.607856, acc: 0.000000]
281: [D loss: 0.227003, acc: 0.937500]  [A loss: 1.115651, acc: 0.437500]
282: [D loss: 1.555810, acc: 0.531250]  [A loss: 9.701564, acc: 0.000000]
283: [D loss: 0.617651, acc: 0.796875]  [A loss: 0.105047, acc: 0.968750]
284: [D loss: 1.708375, acc: 0.500000]  [A loss: 3.821956, acc: 0.062500]
285: [D loss: 0.331801, acc: 0.781250]  [A loss: 4.419779, acc: 0.000000]
286: [D loss: 0.726984, acc: 0.765625]  [A loss: 6.530172, acc: 0.000000]
287: [D loss: 0.251190, acc: 0.890625]  [A loss: 2.007022, acc: 0.093750]
288: [D loss: 1.143055, acc: 0.609375]  [A loss: 7.132246, acc: 0.000000]
289: [D loss: 0.228747, acc: 0.890625]  [A loss: 4.426653, acc: 0.000000]
290: [D loss: 0.696502, acc: 0.687500]  [A loss: 6.418181, acc: 0.000000]
291: [D loss: 0.241579, acc: 0.890625]  [A loss: 3.769459, acc: 0.031250]
292: [D loss: 0.394309, acc: 0.781250]  [A loss: 5.705753, acc: 0.000000]
293: [D loss: 0.180619, acc: 0.937500]  [A loss: 4.088783, acc: 0.000000]
294: [D loss: 0.394506, acc: 0.781250]  [A loss: 4.397465, acc: 0.000000]
295: [D loss: 0.381212, acc: 0.875000]  [A loss: 3.996536, acc: 0.062500]
296: [D loss: 0.667752, acc: 0.703125]  [A loss: 7.467088, acc: 0.000000]
297: [D loss: 0.379819, acc: 0.828125]  [A loss: 0.015809, acc: 1.000000]
298: [D loss: 2.290468, acc: 0.500000]  [A loss: 4.822643, acc: 0.031250]
299: [D loss: 0.228166, acc: 0.875000]  [A loss: 2.926598, acc: 0.031250]
300: [D loss: 0.682761, acc: 0.687500]  [A loss: 6.745136, acc: 0.000000]
301: [D loss: 0.223603, acc: 0.906250]  [A loss: 1.310654, acc: 0.312500]
302: [D loss: 1.202062, acc: 0.546875]  [A loss: 9.488776, acc: 0.000000]
303: [D loss: 0.434394, acc: 0.890625]  [A loss: 0.178632, acc: 0.968750]
304: [D loss: 1.313063, acc: 0.578125]  [A loss: 6.195512, acc: 0.000000]
305: [D loss: 0.221797, acc: 0.906250]  [A loss: 5.232848, acc: 0.031250]
306: [D loss: 0.353528, acc: 0.828125]  [A loss: 5.847310, acc: 0.000000]
307: [D loss: 0.222643, acc: 0.937500]  [A loss: 4.916623, acc: 0.000000]
308: [D loss: 0.870301, acc: 0.671875]  [A loss: 11.549503, acc: 0.000000]
309: [D loss: 0.790383, acc: 0.734375]  [A loss: 0.005038, acc: 1.000000]
310: [D loss: 2.902190, acc: 0.500000]  [A loss: 2.511297, acc: 0.156250]
311: [D loss: 0.600417, acc: 0.734375]  [A loss: 5.878836, acc: 0.000000]
312: [D loss: 0.413223, acc: 0.750000]  [A loss: 8.116454, acc: 0.000000]
313: [D loss: 0.420991, acc: 0.828125]  [A loss: 3.383736, acc: 0.093750]
314: [D loss: 1.148188, acc: 0.593750]  [A loss: 11.344011, acc: 0.000000]
315: [D loss: 0.961756, acc: 0.718750]  [A loss: 0.004245, acc: 1.000000]
316: [D loss: 3.948607, acc: 0.500000]  [A loss: 3.549807, acc: 0.000000]
317: [D loss: 0.780243, acc: 0.687500]  [A loss: 5.946156, acc: 0.000000]
318: [D loss: 0.485380, acc: 0.812500]  [A loss: 4.860140, acc: 0.000000]
319: [D loss: 0.751533, acc: 0.625000]  [A loss: 10.008812, acc: 0.000000]
320: [D loss: 0.611472, acc: 0.828125]  [A loss: 0.371387, acc: 0.843750]
321: [D loss: 2.071461, acc: 0.546875]  [A loss: 10.597710, acc: 0.000000]
322: [D loss: 0.396194, acc: 0.906250]  [A loss: 0.605922, acc: 0.781250]
323: [D loss: 1.927387, acc: 0.500000]  [A loss: 10.651810, acc: 0.000000]
324: [D loss: 0.609508, acc: 0.734375]  [A loss: 0.057642, acc: 0.968750]
325: [D loss: 2.017644, acc: 0.515625]  [A loss: 6.783841, acc: 0.000000]
326: [D loss: 0.323565, acc: 0.859375]  [A loss: 5.342721, acc: 0.062500]
327: [D loss: 0.593631, acc: 0.750000]  [A loss: 8.300624, acc: 0.000000]
328: [D loss: 0.384970, acc: 0.859375]  [A loss: 6.047184, acc: 0.000000]
329: [D loss: 0.702249, acc: 0.734375]  [A loss: 10.652352, acc: 0.000000]
330: [D loss: 0.145596, acc: 0.968750]  [A loss: 4.077322, acc: 0.093750]
331: [D loss: 1.128045, acc: 0.656250]  [A loss: 11.919790, acc: 0.000000]
332: [D loss: 0.688596, acc: 0.828125]  [A loss: 0.097694, acc: 0.968750]
333: [D loss: 2.583857, acc: 0.500000]  [A loss: 10.188841, acc: 0.000000]
334: [D loss: 0.253640, acc: 0.859375]  [A loss: 1.606906, acc: 0.343750]
335: [D loss: 1.369001, acc: 0.578125]  [A loss: 8.583864, acc: 0.000000]
336: [D loss: 0.287751, acc: 0.812500]  [A loss: 2.815350, acc: 0.125000]
337: [D loss: 1.279829, acc: 0.687500]  [A loss: 11.935461, acc: 0.000000]
338: [D loss: 0.680752, acc: 0.750000]  [A loss: 0.053898, acc: 0.968750]
339: [D loss: 2.742249, acc: 0.500000]  [A loss: 6.914377, acc: 0.000000]
340: [D loss: 0.483728, acc: 0.843750]  [A loss: 6.777450, acc: 0.062500]
341: [D loss: 1.017849, acc: 0.718750]  [A loss: 12.646069, acc: 0.000000]
342: [D loss: 0.776619, acc: 0.781250]  [A loss: 0.053883, acc: 0.968750]
343: [D loss: 2.537991, acc: 0.531250]  [A loss: 11.807829, acc: 0.000000]
344: [D loss: 0.406646, acc: 0.812500]  [A loss: 0.389843, acc: 0.875000]
345: [D loss: 1.912966, acc: 0.531250]  [A loss: 12.925210, acc: 0.000000]
346: [D loss: 0.706481, acc: 0.796875]  [A loss: 0.233114, acc: 0.906250]
347: [D loss: 2.419077, acc: 0.515625]  [A loss: 10.001861, acc: 0.000000]
348: [D loss: 0.361625, acc: 0.875000]  [A loss: 5.151998, acc: 0.000000]
349: [D loss: 1.165206, acc: 0.656250]  [A loss: 10.783445, acc: 0.000000]
350: [D loss: 0.320490, acc: 0.828125]  [A loss: 3.776695, acc: 0.125000]
351: [D loss: 1.588616, acc: 0.562500]  [A loss: 13.175921, acc: 0.000000]
352: [D loss: 0.529560, acc: 0.781250]  [A loss: 0.092956, acc: 0.968750]
353: [D loss: 1.606925, acc: 0.593750]  [A loss: 12.369933, acc: 0.000000]
354: [D loss: 0.368605, acc: 0.859375]  [A loss: 1.265335, acc: 0.625000]
355: [D loss: 1.435739, acc: 0.562500]  [A loss: 13.553503, acc: 0.000000]
356: [D loss: 0.617190, acc: 0.843750]  [A loss: 0.282391, acc: 0.843750]
357: [D loss: 1.828822, acc: 0.546875]  [A loss: 12.862505, acc: 0.000000]
358: [D loss: 1.126241, acc: 0.718750]  [A loss: 0.000990, acc: 1.000000]
359: [D loss: 3.977608, acc: 0.515625]  [A loss: 8.610531, acc: 0.000000]
360: [D loss: 0.888312, acc: 0.718750]  [A loss: 10.035023, acc: 0.000000]
361: [D loss: 0.429613, acc: 0.796875]  [A loss: 6.658333, acc: 0.000000]
362: [D loss: 1.467573, acc: 0.656250]  [A loss: 13.581854, acc: 0.000000]
363: [D loss: 1.048773, acc: 0.750000]  [A loss: 0.061015, acc: 0.968750]
364: [D loss: 3.525611, acc: 0.515625]  [A loss: 11.394379, acc: 0.000000]
365: [D loss: 0.262882, acc: 0.906250]  [A loss: 1.365092, acc: 0.531250]
366: [D loss: 2.439530, acc: 0.546875]  [A loss: 13.826286, acc: 0.000000]
367: [D loss: 0.913498, acc: 0.718750]  [A loss: 0.047235, acc: 0.968750]
368: [D loss: 3.105112, acc: 0.515625]  [A loss: 10.878345, acc: 0.000000]
369: [D loss: 0.523732, acc: 0.781250]  [A loss: 7.602048, acc: 0.000000]
370: [D loss: 1.106345, acc: 0.703125]  [A loss: 10.868703, acc: 0.000000]
371: [D loss: 0.383519, acc: 0.875000]  [A loss: 4.876479, acc: 0.187500]
372: [D loss: 2.061786, acc: 0.578125]  [A loss: 15.199855, acc: 0.000000]
373: [D loss: 3.427288, acc: 0.531250]  [A loss: 0.000087, acc: 1.000000]
374: [D loss: 5.844080, acc: 0.500000]  [A loss: 3.992136, acc: 0.187500]
375: [D loss: 2.709003, acc: 0.546875]  [A loss: 11.306837, acc: 0.000000]
376: [D loss: 0.319606, acc: 0.859375]  [A loss: 3.326567, acc: 0.156250]